{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configs\n",
    "yaml_cfg = \"\"\"\n",
    "train_data_path: ./raw_data/time_series_375_prerpocess_en.xlsx\n",
    "test_data_path: ./raw_data/time_series_test_110_preprocess_en.xlsx\n",
    "seed: 42\n",
    "predict_target: LOS # LOS\n",
    "\"\"\"\n",
    "config = OmegaConf.create(yaml_cfg)\n",
    "print(config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "df_train: pd.DataFrame = pd.read_excel(config.train_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\n",
    "- fill `patient_id`\n",
    "- add 2 new columns: total days in hospital (`TOT_DAY`), remaining days in hospital (`LOS`)\n",
    "- only reserve y-m-d for `RE_DATE` column\n",
    "- merge lab tests of the same (patient_id, date)\n",
    "- calculate and save features' statistics information (demographic and lab test data are calculated separately)\n",
    "- normalize data\n",
    "- feature selection\n",
    "- fill missing data (our filling strategy will be described below)\n",
    "- combine above data to time series data (one patient one record)\n",
    "- export to python pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill `patient_id` rows\n",
    "df_train['PATIENT_ID'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# add 2 new columns: total days in hospital (`TOT_DAY`), remaining days in hospital (`LOS`)\n",
    "df_train['LOS'] = (df_train['Discharge time'] - df_train['RE_DATE']).dt.days\n",
    "df_train['TOT_DAY'] = (df_train['Discharge time'] - df_train['Admission time']).dt.days\n",
    "\n",
    "# only reserve y-m-d for `RE_DATE` column\n",
    "df_train['RE_DATE'] = df_train['RE_DATE'].dt.strftime('%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge lab tests of the same (patient_id, date)\n",
    "df_train = df_train.groupby(['PATIENT_ID', 'RE_DATE'], dropna=True, as_index = False).mean()\n",
    "\n",
    "# print(df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labtest_features_str = \"\"\"\n",
    "White blood cell count\n",
    "Red blood cell count\n",
    "Serum potassium\n",
    "calcium\n",
    "hemoglobin\n",
    "Serum chloride\n",
    "serum sodium\n",
    "Platelet count\n",
    "neutrophils(%)\n",
    "neutrophils count\n",
    "mean corpuscular hemoglobin \n",
    "Urea\n",
    "eGFR\n",
    "aspartate aminotransferase\n",
    "Lactate dehydrogenase\n",
    "total protein\n",
    "Alkaline phosphatase\n",
    "Total bilirubin\n",
    "γ-glutamyl transpeptidase\n",
    "glucose\n",
    "Hypersensitive c-reactive protein\n",
    "Prothrombin time\n",
    "Prothrombin activity\n",
    "Hypersensitive cardiac troponinI\n",
    "Amino-terminal brain natriuretic peptide precursor(NT-proBNP)\n",
    "\"\"\"\n",
    "\n",
    "demographic_features_str = \"\"\"\n",
    "age\n",
    "gender\n",
    "\"\"\"\n",
    "\n",
    "labtest_features = [f for f in labtest_features_str.strip().split('\\n')]\n",
    "demographic_features = [f for f in demographic_features_str.strip().split('\\n')]\n",
    "target_features = ['outcome', 'LOS']\n",
    "\n",
    "# print(demographic_features)\n",
    "\n",
    "# print(df_train[features])\n",
    "\n",
    "# we have 2 types of prediction tasks: 1) predict mortality outcome, 2) length of stay\n",
    "\n",
    "# df_train.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features' statistics information\n",
    "\n",
    "def calculate_statistic_info(df, features):\n",
    "    statistic_info = {}\n",
    "    len_df = len(df)\n",
    "    for _, e in enumerate(features):\n",
    "        h = {}\n",
    "        h['count'] = int(df[e].count())\n",
    "        h['missing'] = str(round(float((100-df[e].count()*100/len_df)),3))+\"%\"\n",
    "        h['mean'] = float(df[e].mean())\n",
    "        h['max'] = float(df[e].max())\n",
    "        h['min'] = float(df[e].min())\n",
    "        h['median'] = float(df[e].median())\n",
    "        h['std'] = float(df[e].std())\n",
    "        statistic_info[e] = h\n",
    "    return statistic_info\n",
    "\n",
    "labtest_statistic_info = calculate_statistic_info(df_train, labtest_features)\n",
    "\n",
    "groupby_patientid_df = df_train.groupby(['PATIENT_ID'], dropna=True, as_index = False).mean()\n",
    "\n",
    "labtest_patientwise_statistic_info = calculate_statistic_info(groupby_patientid_df, labtest_features)\n",
    "demographic_statistic_info = calculate_statistic_info(groupby_patientid_df, demographic_features)\n",
    "# print(len(statistic_info))\n",
    "\n",
    "statistic_info = labtest_statistic_info | demographic_statistic_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labtest_patientwise_statistic_info)\n",
    "# observe features\n",
    "to_export_dict = {'name': [], 'missing_rate': [], 'count': [], 'mean': [], 'max': [], 'min': [], 'median': [], 'std': []}\n",
    "for key in labtest_patientwise_statistic_info:\n",
    "    print(key)\n",
    "    detail = labtest_patientwise_statistic_info[key]\n",
    "    to_export_dict['name'].append(key)\n",
    "    to_export_dict['count'].append(detail['count'])\n",
    "    to_export_dict['missing_rate'].append(detail['missing'])\n",
    "    to_export_dict['mean'].append(detail['mean'])\n",
    "    to_export_dict['max'].append(detail['max'])\n",
    "    to_export_dict['min'].append(detail['min'])\n",
    "    to_export_dict['median'].append(detail['median'])\n",
    "    to_export_dict['std'].append(detail['std'])\n",
    "\n",
    "# print(to_export_dict)\n",
    "to_export_df = pd.DataFrame.from_dict(to_export_dict)\n",
    "to_export_df.to_csv('statistic_info.csv')\n",
    "\n",
    "\n",
    "# labtest_features = selected_labtest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize_data(df, features, statistic_info):\n",
    "    df_features = df[features]\n",
    "    df_features = df_features.apply(lambda x: (x - statistic_info[x.name]['mean']) / (statistic_info[x.name]['std']+1e-12))\n",
    "    # print(df_features)\n",
    "    df = pd.concat([df[['PATIENT_ID', 'RE_DATE', 'outcome', 'LOS']], df_features], axis=1)\n",
    "    return df\n",
    "df_train = normalize_data(df_train, demographic_features + labtest_features, statistic_info)\n",
    "# print(df_train)\n",
    "# df_train.to_csv('a.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_data_existing_length(data):\n",
    "    res = 0\n",
    "    for i in data:\n",
    "        if not pd.isna(i):\n",
    "            res += 1\n",
    "    return res\n",
    "# 默认 data 中的元素都是按时间排序的\n",
    "def our_fill(data, mean=0):\n",
    "    data_len = len(data)\n",
    "    data_exist_len = calculate_data_existing_length(data)\n",
    "    if data_len == data_exist_len:\n",
    "        return data\n",
    "    elif data_exist_len == 0:\n",
    "        for i in range(data_len):\n",
    "            data[i] = mean\n",
    "        return data\n",
    "    if pd.isna(data[0]):\n",
    "        # 只考虑length of data > 0\n",
    "        # 这一部分保证了data[0]非空\n",
    "        not_na_pos = 0\n",
    "        for i in range(data_len):\n",
    "            if not pd.isna(data[i]):\n",
    "                not_na_pos = i\n",
    "                break\n",
    "        for i in range(not_na_pos):\n",
    "            data[i] = data[not_na_pos]\n",
    "    for i in range(1, data_len):\n",
    "        if pd.isna(data[i]):\n",
    "            data[i] = data[i-1]\n",
    "    return data\n",
    "# print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing data using our strategy and convert to time series records\n",
    "grouped = df_train.groupby('PATIENT_ID')\n",
    "\n",
    "all_x_demographic = []\n",
    "all_x_labtest = []\n",
    "all_y = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    sorted_group = group.sort_values(by=['RE_DATE'], ascending=True)\n",
    "    # print(df_train)\n",
    "    patient_demographic = []\n",
    "    patient_labtest = []\n",
    "    patient_y = []\n",
    "    for f in labtest_features:\n",
    "        our_fill(sorted_group[f].values)\n",
    "    for _, v in sorted_group.iterrows():\n",
    "        if config.predict_target == 'outcome':\n",
    "            patient_y.append(v[config.predict_target])\n",
    "        elif config.predict_target == 'LOS':\n",
    "            if v['outcome'] == 1:\n",
    "                patient_y.append(70-v['LOS'])\n",
    "            else:\n",
    "                patient_y.append(v['LOS'])\n",
    "        demo = []\n",
    "        lab = []\n",
    "        for f in demographic_features:\n",
    "            demo.append(v[f])\n",
    "        for f in labtest_features:\n",
    "            lab.append(v[f])\n",
    "        patient_labtest.append(lab)\n",
    "        patient_demographic.append(demo)\n",
    "    all_x_demographic.append(patient_demographic[-1])\n",
    "    all_x_labtest.append(patient_labtest)\n",
    "    if config.predict_target == 'outcome':\n",
    "        all_y.append(patient_y[-1])\n",
    "    elif config.predict_target == 'LOS':\n",
    "        all_y.append(patient_y)\n",
    "        \n",
    "\n",
    "# all_x_demographic (二维数组，每个患者对应的静态指标)\n",
    "# all_x_labtest (三维数组，每个患者的各个指标)\n",
    "# all_y (二维患者结局/三维Length of stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(all_x_demographic))\n",
    "# print(len(all_x_labtest))\n",
    "# print(len(all_y))\n",
    "\n",
    "# print('---')\n",
    "# print(len(all_x_demographic[0]))\n",
    "# print(len(all_x_labtest[0]))\n",
    "# # print((all_y[0]))\n",
    "\n",
    "# print('---')\n",
    "# print((all_x_demographic[0]))\n",
    "# print((all_x_labtest[0][0]))\n",
    "# print((all_y[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle format dataset\n",
    "pd.to_pickle(all_x_demographic,f'./processed_data/train_x_demographic.pkl' )\n",
    "pd.to_pickle(all_x_labtest,f'./processed_data/train_x_labtest.pkl' )\n",
    "pd.to_pickle(all_y,f'./processed_data/train_y_{config.predict_target}.pkl' )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dcfc096ef13b95f30f09234d13c16e463dbf760c5a41a06cf3b4dd8ab5dccc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
