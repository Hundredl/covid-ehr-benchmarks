{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.230506Z",
     "start_time": "2021-11-02T02:11:17.941835Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import imp\n",
    "import re\n",
    "import pickle\n",
    "import datetime\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.rnn as rnn_utils\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from utils import utils\n",
    "from utils.readers import InHospitalMortalityReader\n",
    "from utils.preprocessing import Discretizer, Normalizer\n",
    "from utils import metrics\n",
    "from utils import common_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:11:20.237620Z",
     "start_time": "2021-11-02T02:11:20.234044Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = './dataset/tongji/processed_data/'\n",
    "file_name = './ckpt/concare.pth'\n",
    "small_part = False\n",
    "arg_timestep = 1.0\n",
    "batch_size = 256\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.079449Z",
     "start_time": "2021-11-02T02:12:48.067022Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() == True else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "print(\"available device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 27\n",
    "pad_token = np.zeros(input_dim)\n",
    "def pad_sents(sents, pad_token):\n",
    "\n",
    "    sents_padded = []\n",
    "\n",
    "    max_length = max([len(_) for _ in sents])\n",
    "    for i in sents:\n",
    "        padded = list(i) + [pad_token]*(max_length-len(i))\n",
    "        sents_padded.append(np.array(padded))\n",
    "\n",
    "    return np.array(sents_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.282265Z",
     "start_time": "2021-11-02T02:12:48.191901Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss(y_pred, y_true):\n",
    "    loss = torch.nn.BCELoss()\n",
    "    return loss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.355893Z",
     "start_time": "2021-11-02T02:12:48.284802Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):# 返回的是tensor\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "x = pickle.load(open('/home/zhuyh/projects/covid-emr/dataset/tongji/processed_data/train_x_outcome_prediction.pkl', 'rb'))\n",
    "x = np.array(x)\n",
    "\n",
    "y = pickle.load(open('/home/zhuyh/projects/covid-emr/dataset/tongji/processed_data/train_y_outcome_prediction.pkl', 'rb'))\n",
    "y = np.array(y)\n",
    "\n",
    "# print(len(x[0]))\n",
    "x = pad_sents(x, pad_token)\n",
    "# len(x[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.442051Z",
     "start_time": "2021-11-02T02:12:48.358759Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(x, y)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "# print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T02:12:48.189439Z",
     "start_time": "2021-11-02T02:12:48.082871Z"
    }
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GRU, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.gru = nn.GRU(input_size = hidden_dim, hidden_size = hidden_dim, num_layers = 1, batch_first = True)\n",
    "\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "        x = self.linear1(x)\n",
    "\n",
    "        # forward\n",
    "        output, x = self.gru(x)\n",
    "        x = self.linear2(x[0])\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:01.575443Z",
     "start_time": "2021-11-02T02:12:48.445259Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Batch 0: Train Loss = 0.6931\n",
      "Model Loss = 0.6931\n",
      "Epoch 1 Batch 0: Train Loss = 0.6894\n",
      "Model Loss = 0.6894\n",
      "Epoch 2 Batch 0: Train Loss = 0.6839\n",
      "Model Loss = 0.6839\n",
      "Epoch 3 Batch 0: Train Loss = 0.6757\n",
      "Model Loss = 0.6757\n",
      "Epoch 4 Batch 0: Train Loss = 0.6737\n",
      "Model Loss = 0.6737\n",
      "Epoch 5 Batch 0: Train Loss = 0.6727\n",
      "Model Loss = 0.6727\n",
      "Epoch 6 Batch 0: Train Loss = 0.6584\n",
      "Model Loss = 0.6584\n",
      "Epoch 7 Batch 0: Train Loss = 0.6449\n",
      "Model Loss = 0.6449\n",
      "Epoch 8 Batch 0: Train Loss = 0.6190\n",
      "Model Loss = 0.6190\n",
      "Epoch 9 Batch 0: Train Loss = 0.5937\n",
      "Model Loss = 0.5937\n",
      "Epoch 10 Batch 0: Train Loss = 0.5522\n",
      "Model Loss = 0.5522\n",
      "Epoch 11 Batch 0: Train Loss = 0.5096\n",
      "Model Loss = 0.5096\n",
      "Epoch 12 Batch 0: Train Loss = 0.4438\n",
      "Model Loss = 0.4438\n",
      "Epoch 13 Batch 0: Train Loss = 0.3678\n",
      "Model Loss = 0.3678\n",
      "Epoch 14 Batch 0: Train Loss = 0.3075\n",
      "Model Loss = 0.3075\n",
      "Epoch 15 Batch 0: Train Loss = 0.2305\n",
      "Model Loss = 0.2305\n",
      "Epoch 16 Batch 0: Train Loss = 0.1912\n",
      "Model Loss = 0.1912\n",
      "Epoch 17 Batch 0: Train Loss = 0.1608\n",
      "Model Loss = 0.1608\n",
      "Epoch 18 Batch 0: Train Loss = 0.1638\n",
      "Model Loss = 0.1638\n",
      "Epoch 19 Batch 0: Train Loss = 0.1402\n",
      "Model Loss = 0.1402\n",
      "Epoch 20 Batch 0: Train Loss = 0.1550\n",
      "Model Loss = 0.1550\n",
      "Epoch 21 Batch 0: Train Loss = 0.1310\n",
      "Model Loss = 0.1310\n",
      "Epoch 22 Batch 0: Train Loss = 0.1313\n",
      "Model Loss = 0.1313\n",
      "Epoch 23 Batch 0: Train Loss = 0.1401\n",
      "Model Loss = 0.1401\n",
      "Epoch 24 Batch 0: Train Loss = 0.0944\n",
      "Model Loss = 0.0944\n",
      "Epoch 25 Batch 0: Train Loss = 0.1212\n",
      "Model Loss = 0.1212\n",
      "Epoch 26 Batch 0: Train Loss = 0.0941\n",
      "Model Loss = 0.0941\n",
      "Epoch 27 Batch 0: Train Loss = 0.1075\n",
      "Model Loss = 0.1075\n",
      "Epoch 28 Batch 0: Train Loss = 0.1062\n",
      "Model Loss = 0.1062\n",
      "Epoch 29 Batch 0: Train Loss = 0.0914\n",
      "Model Loss = 0.0914\n",
      "Epoch 30 Batch 0: Train Loss = 0.0749\n",
      "Model Loss = 0.0749\n",
      "Epoch 31 Batch 0: Train Loss = 0.0831\n",
      "Model Loss = 0.0831\n",
      "Epoch 32 Batch 0: Train Loss = 0.0929\n",
      "Model Loss = 0.0929\n",
      "Epoch 33 Batch 0: Train Loss = 0.0951\n",
      "Model Loss = 0.0951\n",
      "Epoch 34 Batch 0: Train Loss = 0.0869\n",
      "Model Loss = 0.0869\n",
      "Epoch 35 Batch 0: Train Loss = 0.0871\n",
      "Model Loss = 0.0871\n",
      "Epoch 36 Batch 0: Train Loss = 0.0920\n",
      "Model Loss = 0.0920\n",
      "Epoch 37 Batch 0: Train Loss = 0.0753\n",
      "Model Loss = 0.0753\n",
      "Epoch 38 Batch 0: Train Loss = 0.0826\n",
      "Model Loss = 0.0826\n",
      "Epoch 39 Batch 0: Train Loss = 0.0769\n",
      "Model Loss = 0.0769\n",
      "Epoch 40 Batch 0: Train Loss = 0.0886\n",
      "Model Loss = 0.0886\n",
      "Epoch 41 Batch 0: Train Loss = 0.0785\n",
      "Model Loss = 0.0785\n",
      "Epoch 42 Batch 0: Train Loss = 0.0691\n",
      "Model Loss = 0.0691\n",
      "Epoch 43 Batch 0: Train Loss = 0.0673\n",
      "Model Loss = 0.0673\n",
      "Epoch 44 Batch 0: Train Loss = 0.0613\n",
      "Model Loss = 0.0613\n",
      "Epoch 45 Batch 0: Train Loss = 0.0655\n",
      "Model Loss = 0.0655\n",
      "Epoch 46 Batch 0: Train Loss = 0.0686\n",
      "Model Loss = 0.0686\n",
      "Epoch 47 Batch 0: Train Loss = 0.0641\n",
      "Model Loss = 0.0641\n",
      "Epoch 48 Batch 0: Train Loss = 0.0571\n",
      "Model Loss = 0.0571\n",
      "Epoch 49 Batch 0: Train Loss = 0.0312\n",
      "Model Loss = 0.0312\n",
      "Epoch 50 Batch 0: Train Loss = 0.0618\n",
      "Model Loss = 0.0618\n",
      "Epoch 51 Batch 0: Train Loss = 0.0575\n",
      "Model Loss = 0.0575\n",
      "Epoch 52 Batch 0: Train Loss = 0.0471\n",
      "Model Loss = 0.0471\n",
      "Epoch 53 Batch 0: Train Loss = 0.0595\n",
      "Model Loss = 0.0595\n",
      "Epoch 54 Batch 0: Train Loss = 0.0420\n",
      "Model Loss = 0.0420\n",
      "Epoch 55 Batch 0: Train Loss = 0.0561\n",
      "Model Loss = 0.0561\n",
      "Epoch 56 Batch 0: Train Loss = 0.0105\n",
      "Model Loss = 0.0105\n",
      "Epoch 57 Batch 0: Train Loss = 0.0562\n",
      "Model Loss = 0.0562\n",
      "Epoch 58 Batch 0: Train Loss = 0.0389\n",
      "Model Loss = 0.0389\n",
      "Epoch 59 Batch 0: Train Loss = 0.0380\n",
      "Model Loss = 0.0380\n",
      "Epoch 60 Batch 0: Train Loss = 0.0530\n",
      "Model Loss = 0.0530\n",
      "Epoch 61 Batch 0: Train Loss = 0.0541\n",
      "Model Loss = 0.0541\n",
      "Epoch 62 Batch 0: Train Loss = 0.0536\n",
      "Model Loss = 0.0536\n",
      "Epoch 63 Batch 0: Train Loss = 0.0534\n",
      "Model Loss = 0.0534\n",
      "Epoch 64 Batch 0: Train Loss = 0.0529\n",
      "Model Loss = 0.0529\n",
      "Epoch 65 Batch 0: Train Loss = 0.0530\n",
      "Model Loss = 0.0530\n",
      "Epoch 66 Batch 0: Train Loss = 0.0365\n",
      "Model Loss = 0.0365\n",
      "Epoch 67 Batch 0: Train Loss = 0.0527\n",
      "Model Loss = 0.0527\n",
      "Epoch 68 Batch 0: Train Loss = 0.0355\n",
      "Model Loss = 0.0355\n",
      "Epoch 69 Batch 0: Train Loss = 0.0355\n",
      "Model Loss = 0.0355\n",
      "Epoch 70 Batch 0: Train Loss = 0.0519\n",
      "Model Loss = 0.0519\n",
      "Epoch 71 Batch 0: Train Loss = 0.0400\n",
      "Model Loss = 0.0400\n",
      "Epoch 72 Batch 0: Train Loss = 0.0511\n",
      "Model Loss = 0.0511\n",
      "Epoch 73 Batch 0: Train Loss = 0.0187\n",
      "Model Loss = 0.0187\n",
      "Epoch 74 Batch 0: Train Loss = 0.0327\n",
      "Model Loss = 0.0327\n",
      "Epoch 75 Batch 0: Train Loss = 0.0476\n",
      "Model Loss = 0.0476\n",
      "Epoch 76 Batch 0: Train Loss = 0.0171\n",
      "Model Loss = 0.0171\n",
      "Epoch 77 Batch 0: Train Loss = 0.0306\n",
      "Model Loss = 0.0306\n",
      "Epoch 78 Batch 0: Train Loss = 0.0244\n",
      "Model Loss = 0.0244\n",
      "Epoch 79 Batch 0: Train Loss = 0.0413\n",
      "Model Loss = 0.0413\n",
      "Epoch 80 Batch 0: Train Loss = 0.0389\n",
      "Model Loss = 0.0389\n",
      "Epoch 81 Batch 0: Train Loss = 0.0253\n",
      "Model Loss = 0.0253\n",
      "Epoch 82 Batch 0: Train Loss = 0.0251\n",
      "Model Loss = 0.0251\n",
      "Epoch 83 Batch 0: Train Loss = 0.0382\n",
      "Model Loss = 0.0382\n",
      "Epoch 84 Batch 0: Train Loss = 0.0223\n",
      "Model Loss = 0.0223\n",
      "Epoch 85 Batch 0: Train Loss = 0.0372\n",
      "Model Loss = 0.0372\n",
      "Epoch 86 Batch 0: Train Loss = 0.0377\n",
      "Model Loss = 0.0377\n",
      "Epoch 87 Batch 0: Train Loss = 0.0373\n",
      "Model Loss = 0.0373\n",
      "Epoch 88 Batch 0: Train Loss = 0.0372\n",
      "Model Loss = 0.0372\n",
      "Epoch 89 Batch 0: Train Loss = 0.0370\n",
      "Model Loss = 0.0370\n",
      "Epoch 90 Batch 0: Train Loss = 0.0214\n",
      "Model Loss = 0.0214\n",
      "Epoch 91 Batch 0: Train Loss = 0.0214\n",
      "Model Loss = 0.0214\n",
      "Epoch 92 Batch 0: Train Loss = 0.0211\n",
      "Model Loss = 0.0211\n",
      "Epoch 93 Batch 0: Train Loss = 0.0055\n",
      "Model Loss = 0.0055\n",
      "Epoch 94 Batch 0: Train Loss = 0.0364\n",
      "Model Loss = 0.0364\n",
      "Epoch 95 Batch 0: Train Loss = 0.0203\n",
      "Model Loss = 0.0203\n",
      "Epoch 96 Batch 0: Train Loss = 0.0353\n",
      "Model Loss = 0.0353\n",
      "Epoch 97 Batch 0: Train Loss = 0.0208\n",
      "Model Loss = 0.0208\n",
      "Epoch 98 Batch 0: Train Loss = 0.0205\n",
      "Model Loss = 0.0205\n",
      "Epoch 99 Batch 0: Train Loss = 0.0351\n",
      "Model Loss = 0.0351\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED) #numpy\n",
    "random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED) # cpu\n",
    "torch.cuda.manual_seed(RANDOM_SEED) #gpu\n",
    "torch.backends.cudnn.deterministic=True # cudnn\n",
    "\n",
    "model = GRU(input_dim = input_dim, hidden_dim = 64, output_dim = 1).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "max_roc = 0\n",
    "max_prc = 0\n",
    "train_loss = []\n",
    "train_model_loss = []\n",
    "train_decov_loss = []\n",
    "valid_loss = []\n",
    "valid_model_loss = []\n",
    "valid_decov_loss = []\n",
    "history = []\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "for each_epoch in range(100):\n",
    "    batch_loss = []\n",
    "    model_batch_loss = []\n",
    "    decov_batch_loss = []\n",
    "\n",
    "    model.train()\n",
    " \n",
    "    for step, (batch_x, batch_y) in enumerate(train_loader):   \n",
    "        optimizer.zero_grad()\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "\n",
    "        output = model(batch_x)\n",
    "        \n",
    "        # print(output.shape, batch_y.unsqueeze(-1).shape)\n",
    "        model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "        loss = model_loss\n",
    "        \n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 30 == 0:\n",
    "            print('Epoch %d Batch %d: Train Loss = %.4f'%(each_epoch, step, np.mean(np.array(batch_loss))))\n",
    "            print('Model Loss = %.4f'%(np.mean(np.array(model_batch_loss))))\n",
    "    train_loss.append(np.mean(np.array(batch_loss)))\n",
    "    train_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_loss = []\n",
    "model_batch_loss = []\n",
    "decov_batch_loss = []\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_name) in enumerate(valid_loader):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_demo = []\n",
    "        for i in range(len(batch_name)):\n",
    "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
    "            cur_idx = cur_id + '_' + cur_ep\n",
    "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
    "            batch_demo.append(cur_demo)\n",
    "\n",
    "        batch_demo = torch.stack(batch_demo).to(device)\n",
    "        output,decov_loss = model(batch_x, batch_demo)\n",
    "        \n",
    "        model_loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "\n",
    "        loss = model_loss + 10* decov_loss\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        model_batch_loss.append(model_loss.cpu().detach().numpy())\n",
    "        decov_batch_loss.append(decov_loss.cpu().detach().numpy())\n",
    "        y_pred += list(output.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "        \n",
    "valid_loss.append(np.mean(np.array(batch_loss)))\n",
    "valid_model_loss.append(np.mean(np.array(model_batch_loss)))\n",
    "valid_decov_loss.append(np.mean(np.array(decov_batch_loss)))\n",
    "\n",
    "print(\"\\n==>Predicting on validation\")\n",
    "print('Valid Loss = %.4f'%(valid_loss[-1]))\n",
    "print('valid_model Loss = %.4f'%(valid_model_loss[-1]))\n",
    "print('valid_decov Loss = %.4f'%(valid_decov_loss[-1]))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "ret = metrics.print_metrics_binary(y_true, y_pred)\n",
    "history.append(ret)\n",
    "print()\n",
    "\n",
    "cur_auroc = ret['auroc']\n",
    "\n",
    "if cur_auroc > max_roc:\n",
    "    max_roc = cur_auroc\n",
    "    state = {\n",
    "        'net': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': each_epoch\n",
    "    }\n",
    "    torch.save(state, file_name)\n",
    "    print('\\n------------ Save best model ------------\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:20.964397Z",
     "start_time": "2021-11-02T03:27:16.745558Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_loss = []\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for step, (batch_x, batch_y, batch_name) in enumerate(test_loader):\n",
    "        batch_x = batch_x.float().to(device)\n",
    "        batch_y = batch_y.float().to(device)\n",
    "        batch_demo = []\n",
    "        for i in range(len(batch_name)):\n",
    "            cur_id, cur_ep, _ = batch_name[i].split('_', 2)\n",
    "            cur_idx = cur_id + '_' + cur_ep\n",
    "            cur_demo = torch.tensor(demographic_data[idx_list.index(cur_idx)], dtype=torch.float32)\n",
    "            batch_demo.append(cur_demo)\n",
    "\n",
    "        batch_demo = torch.stack(batch_demo).to(device)\n",
    "        output = model(batch_x, batch_demo)[0]\n",
    "\n",
    "        loss = get_loss(output, batch_y.unsqueeze(-1))\n",
    "        batch_loss.append(loss.cpu().detach().numpy())\n",
    "        y_pred += list(output.cpu().detach().numpy().flatten())\n",
    "        y_true += list(batch_y.cpu().numpy().flatten())\n",
    "\n",
    "print(\"\\n==>Predicting on test\")\n",
    "print('Test Loss = %.4f'%(np.mean(np.array(batch_loss))))\n",
    "y_pred = np.array(y_pred)\n",
    "y_pred = np.stack([1 - y_pred, y_pred], axis=1)\n",
    "test_res = metrics.print_metrics_binary(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:16.741911Z",
     "start_time": "2021-11-02T03:27:01.578022Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = torch.load(file_name)\n",
    "save_epoch = checkpoint['epoch']\n",
    "model.load_state_dict(checkpoint['net'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "model.eval()\n",
    "\n",
    "test_reader = InHospitalMortalityReader(dataset_dir=os.path.join(data_path, 'test'),\n",
    "                                            listfile=os.path.join(data_path, 'test_listfile.csv'),\n",
    "                                            period_length=48.0)\n",
    "test_raw = utils.load_data(test_reader, discretizer, normalizer, small_part, return_names=True)\n",
    "test_dataset = Dataset(test_raw['data'][0], test_raw['data'][1], test_raw['names'])\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-02T03:27:35.542743Z",
     "start_time": "2021-11-02T03:27:20.967136Z"
    }
   },
   "outputs": [],
   "source": [
    "# Bootstrap\n",
    "N = len(y_true)\n",
    "N_idx = np.arange(N)\n",
    "K = 1000\n",
    "\n",
    "auroc = []\n",
    "auprc = []\n",
    "minpse = []\n",
    "for i in range(K):\n",
    "    boot_idx = np.random.choice(N_idx, N, replace=True)\n",
    "    boot_true = np.array(y_true)[boot_idx]\n",
    "    boot_pred = y_pred[boot_idx, :]\n",
    "    test_ret = metrics.print_metrics_binary(boot_true, boot_pred, verbose=0)\n",
    "    auroc.append(test_ret['auroc'])\n",
    "    auprc.append(test_ret['auprc'])\n",
    "    minpse.append(test_ret['minpse'])\n",
    "    print('%d/%d'%(i+1,K))\n",
    "    \n",
    "print('auroc %.4f(%.4f)'%(np.mean(auroc), np.std(auroc)))\n",
    "print('auprc %.4f(%.4f)'%(np.mean(auprc), np.std(auprc)))\n",
    "print('minpse %.4f(%.4f)'%(np.mean(minpse), np.std(minpse)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dcfc096ef13b95f30f09234d13c16e463dbf760c5a41a06cf3b4dd8ab5dccc1"
  },
  "kernelspec": {
   "display_name": "Python (base1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
