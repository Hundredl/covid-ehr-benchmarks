{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global configs\n",
    "yaml_cfg = \"\"\"\n",
    "train_data_path: ./raw_data/hm_demo.csv\n",
    "seed: 42\n",
    "predict_target: outcome # outcome/LOS\n",
    "\"\"\"\n",
    "config = OmegaConf.create(yaml_cfg)\n",
    "print(config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raw data\n",
    "\n",
    "# parser = lambda x: pd.to_datetime(x, format='%d/%m/%Y %H:%M:%S')\n",
    "# df_demo: pd.DataFrame = pd.read_csv(\"./raw_data/hm_demo.csv\", encoding='unicode_escape', sep=\",\", date_parser=parser)\n",
    "df_demo: pd.DataFrame = pd.read_csv(\"./raw_data/hm_demo.csv\", encoding='unicode_escape', sep=\",\", converters={'F_INGRESO_ING' : str})\n",
    "df_labtest: pd.DataFrame = pd.read_csv(\"./raw_data/hm_labtest.csv\", encoding='unicode_escape', sep=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demo['SEX'].replace('MALE', 1, inplace=True)\n",
    "df_demo['SEX'].replace('FEMALE', 0, inplace=True)\n",
    "df_demo.rename(columns={'IDINGRESO': 'PATIENT_ID', 'EDAD': 'AGE', 'DIAGNOSTICO_ING': 'outcome'}, inplace=True)\n",
    "df_demo['outcome'].replace('COVID19 - POSITIVO', 1, inplace=True)\n",
    "df_demo['outcome'].replace('COVID19 - PENDIENTE', 0, inplace=True)\n",
    "\n",
    "cols_str = \"\"\"AGE\tTA_MAX_PRIMERA_URG\tTA_MIN_PRIMERA_URG\tTEMP_PRIMERA_URG\tFC_PRIMERA_URG\tSAT_02_PRIMERA_URG\tGLU_PRIMERA_URG\tDIURESIS_PRIMERA_URG\tHORA_CONSTANTES_ULTIMA_URG\tTA_MAX_ULTIMA_URG\tTA_MIN_ULTIMA_URG\tTEMP_ULTIMA_URG\tFC_ULTIMA_URG\tSAT_02_ULTIMA_URG\tGLU_ULTIMA_URG\"\"\"\n",
    "cols = cols_str.strip().split()\n",
    "df_demo[cols] = df_demo[cols].replace([0, 0.0, '0'], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_demo.to_csv('demo.csv', index=False)\n",
    "# df_demo = df_demo.astype({\"F_INGRESO_ING\": str}, errors='raise')\n",
    "# df_demo['F_INGRESO_ING'] = df_demo['F_INGRESO_ING'].str.replace(r'(\\d+)/(\\d+)/(\\d+)(.*)', r'\\2/\\1/\\3\\4', regex=True)\n",
    "# df_demo['F_INGRESO_ING'] = df_demo['F_INGRESO_ING'].str.replace('/','-')\n",
    "# df_demo['F_INGRESO_ING'] = df_demo['F_INGRESO_ING'].str.replace(' AM','')\n",
    "# df_demo['F_INGRESO_ING'].to_csv('test.csv', index=False)\n",
    "df_demo['F_INGRESO_ING']\n",
    "df_demo['F_ALTA_ING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labtest_features = df_labtest['DETERMINACION/ITEM_LAB'].unique().tolist()\n",
    "labtest_features[0:10]\n",
    "len(labtest_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labtest.rename(columns={'PATIENT ID': 'PATIENT_ID'}, inplace=True)\n",
    "df_labtest = df_labtest[['PATIENT_ID', 'FECHA_PETICION/LAB_DATE', 'DETERMINACION/ITEM_LAB', 'PETICION_LABORATORIO/LAB_NUMBER', 'RESULTADO/VAL_RESULT']].set_index(['PATIENT_ID', 'FECHA_PETICION/LAB_DATE', 'DETERMINACION/ITEM_LAB', 'PETICION_LABORATORIO/LAB_NUMBER'], drop = True).unstack('DETERMINACION/ITEM_LAB')['RESULTADO/VAL_RESULT'].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labtest.to_csv('labtest.csv', index=False)\n",
    "df_labtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_labtest.set_index('PATIENT_ID').join(df_demo.set_index('PATIENT_ID')).reset_index()\n",
    "\n",
    "# df_train.dropna(subset=['FECHA_PETICION/LAB_DATE', 'F_INGRESO_ING', 'F_ALTA_ING'], how='any', inplace=True)\n",
    "\n",
    "# df_train['F_INGRESO_ING'] = df_train['F_INGRESO_ING'].str.replace(r'(\\d+)/(\\d+)/(\\d+)(.*)', r'\\2/\\1/\\3\\4', regex=True)\n",
    "# df_train['F_ALTA_ING'] = df_train['F_ALTA_ING'].str.replace(r'(\\d+)/(\\d+)/(\\d+)(.*)', r'\\2/\\1/\\3\\4', regex=True)\n",
    "\n",
    "# df_train['FECHA_PETICION/LAB_DATE'] = df_train['FECHA_PETICION/LAB_DATE'].str.replace('/','-')\n",
    "# df_train['F_INGRESO_ING'] = df_train['F_INGRESO_ING'].str.replace('/','-')\n",
    "# df_train['F_ALTA_ING'] = df_train['F_ALTA_ING'].str.replace('/','-')\n",
    "\n",
    "# df_train['FECHA_PETICION/LAB_DATE']\n",
    "\n",
    "# df_train['FECHA_PETICION/LAB_DATE'] = pd.to_datetime(df_train['FECHA_PETICION/LAB_DATE']).apply(lambda x: x.date())\n",
    "# df_train['F_INGRESO_ING'] = pd.to_datetime(df_train['F_INGRESO_ING']).apply(lambda x: x.date())\n",
    "# df_train['F_ALTA_ING'] = pd.to_datetime(df_train['F_ALTA_ING']).apply(lambda x: x.date())\n",
    "\n",
    "datetime_error_setting = 'raise' # 'raise' / 'ignore' / 'coerce'\n",
    "# df_train['FECHA_PETICION/LAB_DATE'] = pd.to_datetime(df_train['FECHA_PETICION/LAB_DATE'], format='%d/%m/%Y', errors=datetime_error_setting)\n",
    "df_train['FECHA_PETICION/LAB_DATE'] = pd.to_datetime(df_train['FECHA_PETICION/LAB_DATE'], format='%d-%m-%Y', errors=datetime_error_setting)\n",
    "# df_train['F_INGRESO_ING'] = pd.to_datetime(df_train['F_INGRESO_ING'], format='%m/%d/%Y %H:%M', errors=datetime_error_setting)\n",
    "df_train['F_INGRESO_ING'] = pd.to_datetime(df_train['F_INGRESO_ING'], format='%d/%m/%Y', errors=datetime_error_setting)\n",
    "# df_train['F_ALTA_ING'] = pd.to_datetime(df_train['F_ALTA_ING'], format='%m/%d/%Y %H:%M', errors=datetime_error_setting)\n",
    "df_train['F_ALTA_ING'] = pd.to_datetime(df_train['F_ALTA_ING'], format='%d/%m/%Y', errors=datetime_error_setting)\n",
    "\n",
    "df_train.dropna(subset=['FECHA_PETICION/LAB_DATE', 'F_INGRESO_ING', 'F_ALTA_ING'], how='any', inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['FECHA_PETICION/LAB_DATE'].describe(datetime_is_numeric=True)\n",
    "# df_train['F_ALTA_ING'].describe(datetime_is_numeric=True)\n",
    "# df_train['F_INGRESO_ING'].describe(datetime_is_numeric=True)\n",
    "\n",
    "df_train['LOS'] = (df_train['F_ALTA_ING'] - df_train['FECHA_PETICION/LAB_DATE']).dt.days\n",
    "df_train['TOT_DAY'] = (df_train['F_ALTA_ING'] - df_train['F_INGRESO_ING']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[(df_train['LOS'] >= 0) & (df_train['LOS'] < 35) & (df_train['TOT_DAY'] >= 0 ) & (df_train['TOT_DAY'] < 35 )]\n",
    "# df_train.to_csv('train.csv', index=False)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in labtest_features:\n",
    "    df_train[c] = pd.to_numeric(df_train[c], errors='coerce')\n",
    "\n",
    "df_train = df_train.groupby(['PATIENT_ID', 'FECHA_PETICION/LAB_DATE'], dropna=True, as_index = False).mean()\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "df_train\n",
    "# df_train[labtest_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labtest_features are already defined\n",
    "\n",
    "demographic_features_str = \"\"\"\n",
    "AGE\tSEX TA_MAX_PRIMERA_URG\tTA_MIN_PRIMERA_URG\tTEMP_PRIMERA_URG\tFC_PRIMERA_URG\tSAT_02_PRIMERA_URG\n",
    "TA_MAX_ULTIMA_URG\tTA_MIN_ULTIMA_URG\tTEMP_ULTIMA_URG\tFC_ULTIMA_URG\tSAT_02_ULTIMA_URG\n",
    "UCI_DAYS\n",
    "\"\"\"\n",
    "\n",
    "demographic_features = [f for f in demographic_features_str.strip().split()]\n",
    "target_features = ['outcome', 'LOS']\n",
    "demographic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save features' statistics information\n",
    "def calculate_statistic_info(df, features):\n",
    "    statistic_info = {}\n",
    "    len_df = len(df)\n",
    "    for _, e in enumerate(features):\n",
    "        h = {}\n",
    "        h['count'] = int(df[e].count())\n",
    "        h['missing'] = float((100-df[e].count()*100/len_df))\n",
    "        # print(h['missing'],'% missing')\n",
    "        h['mean'] = float(df[e].mean())\n",
    "        h['max'] = float(df[e].max())\n",
    "        h['min'] = float(df[e].min())\n",
    "        h['median'] = float(df[e].median())\n",
    "        h['std'] = float(df[e].std())\n",
    "        statistic_info[e] = h\n",
    "    return statistic_info\n",
    "\n",
    "labtest_statistic_info = calculate_statistic_info(df_train, labtest_features)\n",
    "\n",
    "groupby_patientid_df = df_train.groupby(['PATIENT_ID'], dropna=True, as_index = False).mean()\n",
    "labtest_patientwise_statistic_info = calculate_statistic_info(groupby_patientid_df, labtest_features)\n",
    "# print(groupby_patientid_df)\n",
    "demographic_statistic_info = calculate_statistic_info(groupby_patientid_df, demographic_features)\n",
    "\n",
    "statistic_info = labtest_statistic_info | demographic_statistic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(labtest_patientwise_statistic_info)\n",
    "# observe features\n",
    "to_export_dict = {'name': [], 'missing_rate': [], 'count': [], 'mean': [], 'max': [], 'min': [], 'median': [], 'std': []}\n",
    "\n",
    "to_export_statistic_info = demographic_statistic_info | labtest_patientwise_statistic_info\n",
    "for key in to_export_statistic_info:\n",
    "    print(key)\n",
    "    detail = to_export_statistic_info[key]\n",
    "    to_export_dict['name'].append(key)\n",
    "    to_export_dict['count'].append(detail['count'])\n",
    "    to_export_dict['missing_rate'].append(detail['missing'])\n",
    "    to_export_dict['mean'].append(detail['mean'])\n",
    "    to_export_dict['max'].append(detail['max'])\n",
    "    to_export_dict['min'].append(detail['min'])\n",
    "    to_export_dict['median'].append(detail['median'])\n",
    "    to_export_dict['std'].append(detail['std'])\n",
    "\n",
    "# print(to_export_dict)\n",
    "to_export_df = pd.DataFrame.from_dict(to_export_dict)\n",
    "to_export_df.to_csv('statistic_info.csv')\n",
    "\n",
    "\n",
    "# labtest_features = selected_labtest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_labtest_features = []\n",
    "for f in labtest_statistic_info:\n",
    "    if labtest_statistic_info[f]['missing'] < 50:\n",
    "        selected_labtest_features.append(f)\n",
    "len(selected_labtest_features)\n",
    "labtest_features = selected_labtest_features\n",
    "# demographic_statistic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "def normalize_data(df, features, statistic_info):\n",
    "    df_features = df[features]\n",
    "    df_features = df_features.apply(lambda x: (x - statistic_info[x.name]['mean']) / (statistic_info[x.name]['std']+1e-12))\n",
    "    # print(df_features)\n",
    "    df = pd.concat([df[['PATIENT_ID', 'FECHA_PETICION/LAB_DATE', 'outcome', 'LOS']], df_features], axis=1)\n",
    "    return df\n",
    "df_train = normalize_data(df_train, demographic_features + labtest_features, statistic_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def is_na(x):\n",
    "#     if math.isnan(x):\n",
    "#         return True\n",
    "#     if pd.isna(x):\n",
    "#         return True\n",
    "#     return False\n",
    "\n",
    "def calculate_data_existing_length(data):\n",
    "    res = 0\n",
    "    for i in data:\n",
    "        if not pd.isna(i):\n",
    "            res += 1\n",
    "    return res\n",
    "# 默认 data 中的元素都是按时间排序的\n",
    "def our_fill(data, mean=0):\n",
    "    data_len = len(data)\n",
    "    data_exist_len = calculate_data_existing_length(data)\n",
    "    if data_len == data_exist_len:\n",
    "        return data\n",
    "    elif data_exist_len == 0:\n",
    "        for i in range(data_len):\n",
    "            data[i] = mean\n",
    "        return data\n",
    "    if pd.isna(data[0]):\n",
    "        # 只考虑length of data > 0\n",
    "        # 这一部分保证了data[0]非空\n",
    "        not_na_pos = 0\n",
    "        for i in range(data_len):\n",
    "            if not pd.isna(data[i]):\n",
    "                not_na_pos = i\n",
    "                break\n",
    "        for i in range(not_na_pos):\n",
    "            data[i] = data[not_na_pos]\n",
    "    for i in range(1, data_len):\n",
    "        if pd.isna(data[i]):\n",
    "            data[i] = data[i-1]\n",
    "    return data\n",
    "# print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing data using our strategy and convert to time series records\n",
    "grouped = df_train.groupby('PATIENT_ID')\n",
    "\n",
    "all_x_demographic = []\n",
    "all_x_labtest = []\n",
    "all_y = []\n",
    "\n",
    "for name, group in grouped:\n",
    "    sorted_group = group.sort_values(by=['FECHA_PETICION/LAB_DATE'], ascending=True)\n",
    "    # print(df_train)\n",
    "    patient_demographic = []\n",
    "    patient_labtest = []\n",
    "    patient_y = []\n",
    "    for f in labtest_features+demographic_features:\n",
    "        our_fill(sorted_group[f].values)\n",
    "    for _, v in sorted_group.iterrows():\n",
    "        if config.predict_target == 'outcome':\n",
    "            patient_y.append(v[config.predict_target])\n",
    "        elif config.predict_target == 'LOS':\n",
    "            if v['outcome'] == 1:\n",
    "                patient_y.append(70-v['LOS'])\n",
    "            else:\n",
    "                patient_y.append(v['LOS'])\n",
    "        demo = []\n",
    "        lab = []\n",
    "        for f in demographic_features:\n",
    "            demo.append(v[f])\n",
    "        for f in labtest_features:\n",
    "            lab.append(v[f])\n",
    "        patient_labtest.append(lab)\n",
    "        patient_demographic.append(demo)\n",
    "    all_x_demographic.append(patient_demographic[-1])\n",
    "    all_x_labtest.append(patient_labtest)\n",
    "    if config.predict_target == 'outcome':\n",
    "        all_y.append(patient_y[-1])\n",
    "    elif config.predict_target == 'LOS':\n",
    "        all_y.append(patient_y)\n",
    "        \n",
    "\n",
    "# all_x_demographic (二维数组，每个患者对应的静态指标)\n",
    "# all_x_labtest (三维数组，每个患者的各个指标)\n",
    "# all_y (二维患者结局/三维Length of stay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pickle format dataset\n",
    "pd.to_pickle(all_x_demographic,f'./processed_data/train_x_demographic.pkl' )\n",
    "pd.to_pickle(all_x_labtest,f'./processed_data/train_x_labtest.pkl' )\n",
    "pd.to_pickle(all_y,f'./processed_data/train_y_{config.predict_target}.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(all_x_demographic).shape # 13 demo features\n",
    "# np.array(all_x_labtest).shape\n",
    "# len(all_x_labtest[0][1]) # 36 labtest features\n",
    "print(all_x_demographic[1])\n",
    "print(all_x_demographic[0][3])\n",
    "print(type(all_x_demographic[0][3]))\n",
    "print(math.isnan(all_x_demographic[1][2]))\n",
    "all_x_demographic[0][3] = 3.0\n",
    "print(all_x_demographic[0][3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.DataFrame({'y':all_y})\n",
    "df_y.describe()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7dcfc096ef13b95f30f09234d13c16e463dbf760c5a41a06cf3b4dd8ab5dccc1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
